name: Stream Scrapers (Enhanced)

on:
  schedule:
    - cron: "*/20 * * * *"  # every 20 minutes
  workflow_dispatch:

jobs:
  setup-env:
    runs-on: ubuntu-latest
    outputs:
      python-version: ${{ steps.out.outputs.py }}
    steps:
      - id: out
        run: echo "py=3.11" >> $GITHUB_OUTPUT

  scraper:
    needs: setup-env
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        script:
          - ppv.py
          # add more scrapers here...

    steps:
      # -------------------------
      # CHECKOUT CODE
      # -------------------------
      - name: Checkout Repository
        uses: actions/checkout@v4

      # -------------------------
      # INSTALL GOOGLE CHROME
      # -------------------------
      - name: Install Google Chrome Stable
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" \
            | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      # -------------------------
      # PYTHON + PLAYWRIGHT
      # -------------------------
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ needs.setup-env.outputs.python-version }}

      - name: Install Python Dependencies
        run: |
          pip install -r requirements.txt
          playwright install chromium
          playwright install-deps

      # -------------------------
      # INSTALL XVFB
      # -------------------------
      - name: Install Xvfb
        run: sudo apt-get install -y xvfb

      # -------------------------
      # RUN SCRAPER WITH DIAGNOSTICS
      # -------------------------
      - name: Run Scraper (headful Chrome with XVFB)
        env:
          DISPLAY: ":99"
          SCRAPER: ${{ matrix.script }}
        run: |
          mkdir -p debug
          echo "ðŸš€ Starting scraper: $SCRAPER"
          xvfb-run --auto-servernum --server-num=99 \
            python3 "$SCRAPER" || echo "âš  Script exited with error"

      # -------------------------
      # SAVE DEBUG ARTIFACTS
      # -------------------------
      - name: Upload Debug Files
        uses: actions/upload-artifact@v4
        with:
          name: debug-${{ matrix.script }}
          path: |
            debug/*.png
            debug/*.html
            debug/*.log
          if-no-files-found: ignore

      # -------------------------
      # COMMIT PLAYLIST CHANGES PER SCRAPER
      # -------------------------
      - name: Commit Playlist
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Detect playlist name -> script name mapping
          base="${{ matrix.script }}"
          playlist="${base%.py}.m3u8"

          echo "Checking playlist: $playlist"

          git add "$playlist"

          if git diff --cached --quiet; then
            echo "No playlist updates."
          else
            git commit -m "Auto-update playlist: $playlist"
            git push
          fi
