name: Sportsonline Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: "*/20 * * * *"   # Runs every 20 minutes

jobs:
  scrape:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      actions: read

    steps:

      - name: ğŸ“ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ğŸ›  Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libnss3 \
            libatk-bridge2.0-0 \
            libgtk-3-0 \
            libgbm1 \
            libasound2 \
            libxshmfence1 \
            libxcomposite1 \
            libxdamage1 \
            libxfixes3 \
            xvfb \
            ffmpeg

      - name: ğŸ­ Install Playwright + Chromium
        run: |
          pip install playwright
          playwright install chromium --with-deps

      - name: ğŸ“¦ Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: â–¶ï¸ Run scraper with retries + timeout
        run: |
          echo "Running Sportsonline scraper..."
          for attempt in 1 2 3; do
            echo "Attempt $attempt..."
            timeout 240 python3 sportsonline.py && break
            echo "Attempt $attempt failed."
            sleep 5
          done

      - name: ğŸ“ Commit & Push changes
        if: success()
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "actions@github.com"

          git add -A
          git commit -m "Auto-update sportsonline playlists $(date -u)" || echo "No changes to commit"
          git push
